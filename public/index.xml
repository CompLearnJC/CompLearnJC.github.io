<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CompLearnJC</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on CompLearnJC</description>
    <generator>Hugo -- 0.133.1</generator>
    <language>en-us</language>
    <copyright>CompLearnJC</copyright>
    <lastBuildDate>Thu, 12 Sep 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Compositional Learning</title>
      <link>http://localhost:1313/blog/posts/compositional-learning/</link>
      <pubDate>Thu, 12 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/posts/compositional-learning/</guid>
      <description>Overview Compositional learning, inspired by the innate human ability to break down and generate complex ideas from simpler building blocks, seeks to empower machines with similar capacities. By recombining learned components, this approach significantly enhances generalization, allowing models to handle out-of-distribution (OOD) samples in real-world scenarios. This promising capability has sparked a surge of interest in several fields, including:
üîç Object-centric learning ‚Äì enabling models to recognize and manipulate individual objects in complex environments.</description>
    </item>
    <item>
      <title>CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching</title>
      <link>http://localhost:1313/blog/posts/comat-aligning-text-to-image-diffusion-model-with-image-to-text-concept-matching/</link>
      <pubDate>Sun, 08 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/posts/comat-aligning-text-to-image-diffusion-model-with-image-to-text-concept-matching/</guid>
      <description>Dongzhi Jiang, Guanglu Song, Xiaoshi Wu, Renrui Zhang, Dazhong Shen, Zhuofan Zong, Yu Liu, Hongsheng Li</description>
    </item>
    <item>
      <title>Understanding and Mitigating Compositional Issues in Text-to-Image Generative Models</title>
      <link>http://localhost:1313/blog/posts/understanding-and-mitigating-compositional-issues-in-text-to-image-generativ-models/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/posts/understanding-and-mitigating-compositional-issues-in-text-to-image-generativ-models/</guid>
      <description>Arman Zarei, Keivan Rezaei, Samyadeep Basu, Mehrdad Saberi, Mazda Moayeri, Priyatham Kattakinda, Soheil Feizi</description>
    </item>
    <item>
      <title>Compositional Visual Generation with Composable Diffusion Models</title>
      <link>http://localhost:1313/blog/posts/compositional-visual-generation-with-composable-diffusion-models/</link>
      <pubDate>Wed, 31 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/posts/compositional-visual-generation-with-composable-diffusion-models/</guid>
      <description>Nan Liu, Shuang Li, Yilun Du, Antonio Torralba, and Joshua B. Tenenbaum</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>Compositional Learning Journal Club ‚ùì What Are Compositional Problems? Compositionality refers to the ability to understand and create new combinations using familiar components, functioning much like an algebraic process. While the human brain is naturally adept at learning and applying compositional principles, neural networks (NNs) struggle with this capability. NNs find it difficult to identify and store shared skills across different tasks and to recombine them in a structured, hierarchical way to tackle new problems.</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/join/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/join/</guid>
      <description>ü§ù Join US üìä Presentation If you&amp;rsquo;re interested in joining our discussions or contributing to our research efforts, feel free to reach out or follow our GitHub for updates on upcoming meetings and topics.
Follow us: @RIML Lab</description>
    </item>
    <item>
      <title> Sessions Schedule</title>
      <link>http://localhost:1313/schedule/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/schedule/</guid>
      <description>Time: Sunday at 17:00 (UTC+3:30) Online: vc.sharif.edu/ch/rohban Subject Presenter Date Time Type A Cat Is A Cat (Not A Dog!): Unraveling Information Mix-ups in Text-to-Image Encoders through Causal Analysis and Embedding Optimization Amir Kasaei 2025/06/10 16:45 (UTC+3:30) Public Erasing Undesirable Concepts in Diffusion Models with Adversarial Preservation Aryan Komaei 2025/06/03 16:45 (UTC+3:30) Public Data Unlearning in Diffusion Models Aryan Komaei 2025/05/27 16:45 (UTC+3:30) Public Boosting Alignment for Post-Unlearning Text-to-Image Generative Models Aryan Komaei 2025/05/20 16:45 (UTC+3:30) Public Correcting Diffusion Generation through Resampling Ali Aghayari 2025/02/04 17:30 (UTC+3:30) Public Can We Generate Images with CoT?</description>
    </item>
  </channel>
</rss>
