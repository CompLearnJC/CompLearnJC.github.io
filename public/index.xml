<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CompLearnJC</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on CompLearnJC</description>
    <generator>Hugo -- 0.133.1</generator>
    <language>en-us</language>
    <copyright>CompLearnJC</copyright>
    <lastBuildDate>Thu, 12 Sep 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Compositional Learning</title>
      <link>http://localhost:1313/blog/posts/compositional-learning/</link>
      <pubDate>Thu, 12 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/posts/compositional-learning/</guid>
      <description>Overview Compositional learning, inspired by the innate human ability to break down and generate complex ideas from simpler building blocks, seeks to empower machines with similar capacities. By recombining learned components, this approach significantly enhances generalization, allowing models to handle out-of-distribution (OOD) samples in real-world scenarios. This promising capability has sparked a surge of interest in several fields, including:
üîç Object-centric learning ‚Äì enabling models to recognize and manipulate individual objects in complex environments.</description>
    </item>
    <item>
      <title>CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching</title>
      <link>http://localhost:1313/blog/posts/comat-aligning-text-to-image-diffusion-model-with-image-to-text-concept-matching/</link>
      <pubDate>Sun, 08 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/posts/comat-aligning-text-to-image-diffusion-model-with-image-to-text-concept-matching/</guid>
      <description>Dongzhi Jiang, Guanglu Song, Xiaoshi Wu, Renrui Zhang, Dazhong Shen, Zhuofan Zong, Yu Liu, Hongsheng Li</description>
    </item>
    <item>
      <title>Understanding and Mitigating Compositional Issues in Text-to-Image Generative Models</title>
      <link>http://localhost:1313/blog/posts/understanding-and-mitigating-compositional-issues-in-text-to-image-generativ-models/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/posts/understanding-and-mitigating-compositional-issues-in-text-to-image-generativ-models/</guid>
      <description>Arman Zarei, Keivan Rezaei, Samyadeep Basu, Mehrdad Saberi, Mazda Moayeri, Priyatham Kattakinda, Soheil Feizi</description>
    </item>
    <item>
      <title>Compositional Visual Generation with Composable Diffusion Models</title>
      <link>http://localhost:1313/blog/posts/compositional-visual-generation-with-composable-diffusion-models/</link>
      <pubDate>Wed, 31 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/posts/compositional-visual-generation-with-composable-diffusion-models/</guid>
      <description>Nan Liu, Shuang Li, Yilun Du, Antonio Torralba, and Joshua B. Tenenbaum</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>Compositional Learning Journal Club ‚ùì What Are Compositional Problems? Compositionality refers to the ability to understand and create new combinations using familiar components, functioning much like an algebraic process. While the human brain is naturally adept at learning and applying compositional principles, neural networks (NNs) struggle with this capability. NNs find it difficult to identify and store shared skills across different tasks and to recombine them in a structured, hierarchical way to tackle new problems.</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/join/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/join/</guid>
      <description>ü§ù Join US üìä Presentation If you&amp;rsquo;re interested in joining our discussions or contributing to our research efforts, feel free to reach out or follow our GitHub for updates on upcoming meetings and topics.
Follow us: @RIML Lab</description>
    </item>
    <item>
      <title> Sessions Schedule</title>
      <link>http://localhost:1313/schedule/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/schedule/</guid>
      <description> Time: Sunday at 17:00 (UTC+3:30) Online: vc.sharif.edu/ch/rohban Subject Presenter Date Time Type InitNO: Boosting Text-to-Image Diffusion Models via Initial Noise Optimization Amir Kasaei 2024/10/20 17:00 (UTC+3:30) Public A semiotic methodology for assessing the compositional effectiveness of generative text-to-image models Amir Kasaei 2024/10/06 17:00 (UTC+3:30) Public ComAlign: Compositional Alignment in Vision-Language Models Ali Abdollahi 2024/09/28 10:00 (UTC+3:30) Private Divide, Evaluate, and Refine: Evaluating and Improving Text-to-Image Alignment with Iterative VQA Feedback Amir Kasaei 2024/09/15 14:00 (UTC+3:30) Public CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching Arash Marioriyad 2024/09/08 15:30 (UTC+3:30) Public Understanding and Mitigating Compositional Issues in Text-to-Image Generative Models Dr MH Rohban 2024/09/01 15:30 (UTC+3:30) Private </description>
    </item>
  </channel>
</rss>
