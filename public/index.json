[{"content":"Overview Compositional learning, inspired by the innate human ability to break down and generate complex ideas from simpler building blocks, seeks to empower machines with similar capacities. By recombining learned components, this approach significantly enhances generalization, allowing models to handle out-of-distribution (OOD) samples in real-world scenarios. This promising capability has sparked a surge of interest in several fields, including:\n🔍 Object-centric learning – enabling models to recognize and manipulate individual objects in complex environments. 🧩 Compositional generalization – allowing models to generalize to unseen combinations of known concepts. 🧠 Compositional reasoning – equipping machines with the ability to infer new knowledge from existing components. Key Applications Compositional learning has found exciting applications across diverse domains, such as:\n🌍 Machine translation – enabling smoother cross-lingual communication. 🔄 Cross-lingual transfer – transferring knowledge between languages to boost performance on low-resource languages. 🧾 Semantic parsing – converting natural language into structured data. ✍️ Controllable text generation – offering fine-grained control over generated content. 📚 Factual knowledge reasoning – reasoning based on known facts and knowledge bases. 🖼️ Image captioning – generating detailed descriptions of visual content. 🎨 Text-to-image generation – producing images from textual descriptions. 👁️ Visual reasoning – making logical inferences based on visual information. 🎤 Speech processing – improving comprehension and generation in voice-based systems. 🎮 Reinforcement learning – learning through trial and error in interactive environments. Challenges Despite these strides, significant challenges remain:\n📉 Compositional generalization gaps – Even the most advanced models, including large language models (LLMs), struggle to fully generalize compositional reasoning in dynamic and rapidly changing real-world environments. 🌪️ Handling real-world distributions – Many models falter when faced with complex, evolving real-world data, limiting their applicability in certain high-stakes scenarios. Closing these gaps will be crucial for future advancements in AI, as researchers continue to push the boundaries of machine learning and artificial intelligence.\nRelated Papers Name Compositional visual generation with composable diffusion models Training-free structured diffusion guidance for compositional text-to-image synthesis Attend-and-excite: Attentionbased semantic guidance for text-to-image diffusion models Compositional Visual Generation with Composable Diffusion Models ","permalink":"http://localhost:1313/blog/posts/compositional-learning/","summary":"Overview Compositional learning, inspired by the innate human ability to break down and generate complex ideas from simpler building blocks, seeks to empower machines with similar capacities. By recombining learned components, this approach significantly enhances generalization, allowing models to handle out-of-distribution (OOD) samples in real-world scenarios. This promising capability has sparked a surge of interest in several fields, including:\n🔍 Object-centric learning – enabling models to recognize and manipulate individual objects in complex environments.","title":"Compositional Learning"},{"content":"","permalink":"http://localhost:1313/blog/posts/comat-aligning-text-to-image-diffusion-model-with-image-to-text-concept-matching/","summary":"","title":"CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching"},{"content":"Abstract ","permalink":"http://localhost:1313/blog/posts/understanding-and-mitigating-compositional-issues-in-text-to-image-generativ-models/","summary":"Abstract ","title":"Understanding and Mitigating Compositional Issues in Text-to-Image Generative Models"},{"content":"Abstract This paper studies the problem of zero-shot generalization in reinforcement learning and introduces an algorithm that trains an ensamble of maximum reward seeking agents and an maximum entropy agent. At test time, either the ensemble agrees on an action, and we generalize well, or we take exploratory actions with the help of maximum entropy agent and drive us to a novel part of the state space, where the ensemble may potentially agree again. This method combined with an invariance based approach achieves new state-of-the-art results on ProcGen.\n","permalink":"http://localhost:1313/blog/posts/compositional-visual-generation-with-composable-diffusion-models/","summary":"Abstract This paper studies the problem of zero-shot generalization in reinforcement learning and introduces an algorithm that trains an ensamble of maximum reward seeking agents and an maximum entropy agent. At test time, either the ensemble agrees on an action, and we generalize well, or we take exploratory actions with the help of maximum entropy agent and drive us to a novel part of the state space, where the ensemble may potentially agree again.","title":"Compositional Visual Generation with Composable Diffusion Models"},{"content":"\rCompositional Learning Journal Club ❓ What Are Compositional Problems? Compositionality refers to the ability to understand and create new combinations using familiar components, functioning much like an algebraic process. While the human brain is naturally adept at learning and applying compositional principles, neural networks (NNs) struggle with this capability. NNs find it difficult to identify and store shared skills across different tasks and to recombine them in a structured, hierarchical way to tackle new problems. This approach is crucial for tasks like:\n🗣️ Natural Language Understanding: Interpreting and generating language by combining words and phrases in meaningful ways. 👁️ Vision and Perception: Generating, recognizing and assembling different elements of a scene, such as objects and their relationships. 🧩 Reasoning and Planning: Decomposing complex decisions into a series of logical steps or actions. In essence, compositional learning seeks to enable AI systems to think in a modular and structured way, much like how humans break down and understand complex concepts.\nThe inability of Deep Learning to perform compositional learning is one of the main reasons for Deep Learning’s most critical limitations, including the need to feed them tons of data\n📝 About Us We gather to discuss and analyze cutting-edge research papers, share insights, and collaborate on ideas related to compositional learning. Whether you\u0026rsquo;re a seasoned researcher or just starting out in the field, our goal is to foster a deep understanding of the principles and challenges of compositionality in AI @ RIML Lab\n📚 Activities 📖 Paper Discussions: Regular meetings where we discuss recent papers on compositional learning. 🔍 Research Insights: Share and discuss key findings and ideas from ongoing research. 🤝 Collaborative Exploration: Engage in collaborative discussions to explore new directions in compositional AI. 👥 Members Dr Mohammad Hossein Rohban Amir Kasaei Arash Marioriyad 🚀 How to Join If you\u0026rsquo;re interested in joining our discussions or contributing to our research efforts, feel free to reach out or follow our GitHub for updates on upcoming meetings and topics.\nYou can check meeting announcements @ RIML Lab Channel\n📧 Contact For more information, reach out to us via Telegram:\namirkasaei arashmarioriyad ","permalink":"http://localhost:1313/about/","summary":"Compositional Learning Journal Club ❓ What Are Compositional Problems? Compositionality refers to the ability to understand and create new combinations using familiar components, functioning much like an algebraic process. While the human brain is naturally adept at learning and applying compositional principles, neural networks (NNs) struggle with this capability. NNs find it difficult to identify and store shared skills across different tasks and to recombine them in a structured, hierarchical way to tackle new problems.","title":""},{"content":" Time: Every Sunday at 17:00 (UTC+3:30) Online: vc.sharif.edu/ch/rohban Subject Presenter Date Time Type A semiotic methodology for assessing the compositional effectiveness of generative text-to-image models Amir Kasaei 2024/10/06 17:00 (UTC+3:30) Public ComAlign: Compositional Alignment in Vision-Language Models Ali Abdollahi 2024/09/28 10:00 (UTC+3:30) Private Divide, Evaluate, and Refine: Evaluating and Improving Text-to-Image Alignment with Iterative VQA Feedback Amir Kasaei 2024/09/15 14:00 (UTC+3:30) Public CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching Arash Marioriyad 2024/09/08 15:30 (UTC+3:30) Public Understanding and Mitigating Compositional Issues in Text-to-Image Generative Models Dr MH Rohban 2024/09/01 15:30 (UTC+3:30) Private ","permalink":"http://localhost:1313/schedule/","summary":" Time: Every Sunday at 17:00 (UTC+3:30) Online: vc.sharif.edu/ch/rohban Subject Presenter Date Time Type A semiotic methodology for assessing the compositional effectiveness of generative text-to-image models Amir Kasaei 2024/10/06 17:00 (UTC+3:30) Public ComAlign: Compositional Alignment in Vision-Language Models Ali Abdollahi 2024/09/28 10:00 (UTC+3:30) Private Divide, Evaluate, and Refine: Evaluating and Improving Text-to-Image Alignment with Iterative VQA Feedback Amir Kasaei 2024/09/15 14:00 (UTC+3:30) Public CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching Arash Marioriyad 2024/09/08 15:30 (UTC+3:30) Public Understanding and Mitigating Compositional Issues in Text-to-Image Generative Models Dr MH Rohban 2024/09/01 15:30 (UTC+3:30) Private ","title":" Sessions Schedule"}]